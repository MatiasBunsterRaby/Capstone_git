{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos el dataset y normalizamos las columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación de K-MEANS al CRISIS\n",
    "* En este notebook 'KMeans_general', analizamos el dataset general en base a los valores de las etiquetas de los programas presidenciales. PAra cada país, para cada año en que tuvo elecciones, se ponderó cada variable por el % de votos que sacó cada programa; de esta manera tenemos un registro por país por año.\n",
    "* Dado que hay algunos países en que la suma de las variables 'per' no es 100%, se normalizaron de forma de que sumaran 100%\n",
    "* A fin de contar con una buena masa de datos, sólo se considerá las variables per principales ('per' + 3 dígitos). En total 46 variables.\n",
    "* Se aplicó PCA para reducir las dimensiones\n",
    "* Aplicamos K-MEANS\n",
    "* Hicimos análisis de los países-años en cada cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Filtrar y Normalizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el dataset principal\n",
    "file_path = './data/MP_Dataset_KMeans.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Definir el rango temporal\n",
    "desde = 2000  # Año de inicio\n",
    "hasta = 2010  # Año de fin\n",
    "\n",
    "# Seleccionar las variables asociadas al aspecto 'CRISIS_FINANCIERA_2008'\n",
    "aspecto_filtro = 'CRISIS_FINANCIERA_2008'\n",
    "variables_aspecto = df_aspectos[df_aspectos['aspecto'] == aspecto_filtro][['var_1', 'var_2', 'var_3', 'var_4']].dropna(axis=1).values.flatten()\n",
    "\n",
    "# Filtrar las columnas relevantes y el rango temporal\n",
    "columns_relevant = ['agno', 'countryname'] + list(variables_aspecto)\n",
    "df_filtered = df[(df['agno'] >= desde) & (df['agno'] <= hasta)][columns_relevant].copy()\n",
    "\n",
    "# Validar si las variables seleccionadas suman 1 y normalizar si es necesario\n",
    "df_filtered['per_sum'] = df_filtered[variables_aspecto].sum(axis=1)\n",
    "rows_to_normalize = df_filtered['per_sum'] != 1.0\n",
    "df_filtered.loc[rows_to_normalize, variables_aspecto] = df_filtered.loc[rows_to_normalize, variables_aspecto].div(df_filtered.loc[rows_to_normalize, 'per_sum'], axis=0)\n",
    "df_filtered.drop(columns=['per_sum'], inplace=True)\n",
    "\n",
    "# Verificar la normalización\n",
    "print(f\"¿Todas las filas normalizadas correctamente? {df_filtered[variables_aspecto].sum(axis=1).round(6).eq(1).all()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Realizar PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_filtered[variables_aspecto])\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Crear un DataFrame con los resultados de PCA\n",
    "df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2', 'PC3'])\n",
    "df_pca['countryname'] = df_filtered['countryname']\n",
    "df_pca['agno'] = df_filtered['agno']\n",
    "\n",
    "# Visualizar varianza explicada\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o')\n",
    "plt.title('Varianza explicada por componente principal')\n",
    "plt.xlabel('Componente principal')\n",
    "plt.ylabel('Proporción de varianza explicada')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Elbow + K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Calcular WCSS para determinar el número óptimo de clústeres\n",
    "max_k = 10\n",
    "wcss = []\n",
    "for k in range(1, max_k + 1):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(data_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Graficar el método del codo\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, max_k + 1), wcss, marker='o')\n",
    "plt.title('Método del codo')\n",
    "plt.xlabel('Número de clústeres')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Encontrar el codo automáticamente\n",
    "kl = KneeLocator(range(1, max_k + 1), wcss, curve=\"convex\", direction=\"decreasing\")\n",
    "optimal_k = kl.knee\n",
    "print(f\"El número óptimo de clústeres según el método del codo es: {optimal_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Visualizar clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar K-Means con el número óptimo de clústeres\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df_pca['cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Graficar los clústeres en 2D\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_pca[df_pca['cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['PC1'], cluster_data['PC2'], label=f'Cluster {cluster}', alpha=0.7)\n",
    "plt.title(f'Clústeres para {aspecto_filtro} (2D)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Graficar los clústeres en 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_pca[df_pca['cluster'] == cluster]\n",
    "    ax.scatter(cluster_data['PC1'], cluster_data['PC2'], cluster_data['PC3'], label=f'Cluster {cluster}', alpha=0.7)\n",
    "ax.set_title(f'Clústeres para {aspecto_filtro} (3D)')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Análisis de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar centroides\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(f\"Centroides de los clústeres:\\n{pd.DataFrame(centroids, columns=variables_aspecto)}\")\n",
    "\n",
    "# Revisar países y años en cada clúster\n",
    "clustered_data = pd.concat([df_filtered, df_pca[['cluster']]], axis=1)\n",
    "for cluster in range(optimal_k):\n",
    "    print(f\"\\n--- Cluster {cluster} ---\")\n",
    "    cluster_subset = clustered_data[clustered_data['cluster'] == cluster]\n",
    "    print(f\"Número de Programas: {len(cluster_subset)}\")\n",
    "    print(f\"Países: {', '.join(cluster_subset['countryname'].unique())}\")\n",
    "    print(f\"Años en este clúster: {', '.join(map(str, sorted(cluster_subset['agno'].unique())))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DatascienceUDD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
